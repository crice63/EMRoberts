{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The routine below produces speech from my computer speaker (if the quiet flag, `-q`, is omitted), and has the unicode IPA output in a variable. I found and adapted a program to syllabify the ipa forms.\n",
    "\n",
    "To run this script you need eSpeak set up and know the full path to espeak\\command_line\\. I put it in my PATH so I don't need to put it in the code. \n",
    "\n",
    "For English, stress is needed for correct syllabification. As far as I know, eSpeak output for a single word knows nothing about stress-determined variants in English like REcord/reCORD, but it must do some PoS marking because in clauses it will usually get the right form.\n",
    "\n",
    "Under `subprocess` the espeak args are a Python list. Apparently it is best to build the whole list from vars.\n",
    "My Anaconda is -V 3.6.7, so I can't use the recommended `capture_output` parameter added in 3.7. The `universal_newlines` parameter causes an encoding fault in `subprocess somewhere`, so I decode stdout manually after it returns. That is also why the rstrip() is needed, to remove the \\r\\n that eSpeak appends. I don't know if decode removes the utf8 byte at the front of each line but I think it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IPA transcription of record is: ɹ_ˈɛ_k_ɚ_d\n",
      "The syllabification of record is: ɹ-ˈɛ-.k-ɚ-d\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import syllabify_ipa as s\n",
    "\n",
    "text = \"record\"\n",
    "#outfile = 'C:\\Users\\clair\\Dropbox\\photrans\\practice1.txt'\n",
    "\n",
    "# eSpeak is in my path so I don't need to specify the direct path\n",
    "cp = subprocess.run(['espeak', '-v', 'en-us', '-q', '-x', '--ipa=3', text], \n",
    "                    stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "ipatext = cp.stdout.decode(\"utf-8\").strip()\n",
    "print (f'The IPA transcription of {text} is: {ipatext}')\n",
    "syltext = s.syllabify(ipatext.split('_'))\n",
    "\n",
    "# Syllabify output is a list of [[onset][nucleus][coda]]. Any missing parts \n",
    "# are indicated by hyphens. Syllables are separated by dots. Stresses are\n",
    "# retained. \n",
    "\n",
    "print (f'The syllabification of {text} is: {s.pprint(syltext)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fixUnder notebook, you can put the poems in `texts/UnderTree/` with some TEI tags. This script uses BeautifulSoup to grab a file, parse the tree structure and access specific parts. The poem name is hard coded right now--you can change it to any one you wish.\n",
    "\n",
    "syllabify_ipa.py must be in your working directory because it is written to run as a module. The import statment is at the top of the script. I converted it to work on ipa so it shoul dbe considered a work in progress. Output should be scanned for errors. Any error that affects finaly syllable structure will be labeled \"other\" in the rhyme groupings, so anythgn that says other means that either the groupings are incomplete or the syllabification was wrong.\n",
    "\n",
    "5-30-21: The current challenge is printing out--yep, encoding. Python 3 doesn't like printing to Windows, so I have to figure something out so the IPA characters are accessible. It might not be possible in Windows but I am still trying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<lg n=\"25\" type=\"poem\" xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
      " <head>\n",
      "  MUMPS\n",
      " </head>\n",
      " <lg n=\"1\" type=\"stanza\">\n",
      "  <l n=\"1\" phon=\"aɪ hɐd ɐ fˈiːlɪŋ ɪn maɪ nˈɛk\" rhyme=\"A\">\n",
      "   I had a feeling in my neck,\n",
      "  </l>\n",
      "  <l n=\"2\" phon=\"ænd ɑːnðə sˈaɪdz wɜː tˈuː bˈɪɡ bˈʌmps\" rhyme=\"B\" rime=\"ʌmps\" type=\"strong\" vc_structure=\"VCCC\">\n",
      "   And on the sides were two big bumps;\n",
      "  </l>\n",
      "  <l n=\"3\" phon=\"aɪ kˌʊdənt swˈɑːloʊ ˈɛnɪθˌɪŋ\" rhyme=\"C\">\n",
      "   I couldn't swallow anything\n",
      "  </l>\n",
      "  <l n=\"4\" phon=\"æt ˈɔːl bɪkˈʌz aɪ hɐd ðə mˈʌmps\" rhyme=\"B\" rime=\"ʌmps\" type=\"strong\" vc_structure=\"VCCC\">\n",
      "   At all because I had the mumps.\n",
      "  </l>\n",
      " </lg>\n",
      " <lg n=\"2\" type=\"stanza\">\n",
      "  <l n=\"5\" phon=\"ænd mˈʌðɚ tˈaɪd ɪt wɪð ɐ pˈiːs\" rhyme=\"D\">\n",
      "   And Mother tied it with a piece,\n",
      "  </l>\n",
      "  <l n=\"6\" phon=\"ænd ðˈɛn ʃiː tˈaɪd ˌʌp wɪl ænd dʒˈɑːn\" rhyme=\"E\" rime=\"ɑːn\" type=\"strong\" vc_structure=\"VC\">\n",
      "   And then she tied up Will and John,\n",
      "  </l>\n",
      "  <l n=\"7\" phon=\"ænd nˈoʊwˈʌn ˈɛls bˌʌt dˈɪk wʌz lˈɛft\" rhyme=\"F\">\n",
      "   And no one else but Dick was left\n",
      "  </l>\n",
      "  <l n=\"8\" phon=\"ðæt dˈɪdnt hæv ɐ mˈʌmp ɹˈæɡ ˈɑːn\" rhyme=\"E\" rime=\"ɑːn\" type=\"strong\" vc_structure=\"VC\">\n",
      "   That didn't have a mump rag on.\n",
      "  </l>\n",
      " </lg>\n",
      " <lg n=\"3\" type=\"stanza\">\n",
      "  <l n=\"9\" phon=\"hiː tˈiːzd æt ˌʌs ænd lˈæfd æt ˌʌs\" rhyme=\"G\">\n",
      "   He teased at us and laughed at us,\n",
      "  </l>\n",
      "  <l n=\"10\" phon=\"ænd sˈɛd wɛnˌɛvɚ hiː wɛnt bˈaɪ\" rhyme=\"H\" rime=\"aɪ\" type=\"weak\" vc_structure=\"V\">\n",
      "   And said, whenever he went by,\n",
      "  </l>\n",
      "  <l n=\"11\" phon=\" ɪts vˈɪnᵻɡɚ ænd lˈɛmən dɹˈɑːps\" rhyme=\"I\">\n",
      "   \"It's vinegar and lemon drops\n",
      "  </l>\n",
      "  <l n=\"12\" phon=\"ænd pˈɪkəlz dʒˈʌst tə mˌeɪk ˌʌs kɹˈaɪ\" rhyme=\"H\" rime=\"aɪ\" type=\"weak\" vc_structure=\"V\">\n",
      "   And pickles!\" just to make us cry.\n",
      "  </l>\n",
      " </lg>\n",
      " <lg n=\"4\" type=\"stanza\">\n",
      "  <l n=\"13\" phon=\"bˌʌt tˈuːzdeɪ dˈɪk wʌz vˈɛɹi sˈæd\" rhyme=\"J\">\n",
      "   But Tuesday Dick was very sad\n",
      "  </l>\n",
      "  <l n=\"14\" phon=\"ænd kɹˈaɪd bɪkˈʌz hɪz nˈɛk wʌz sˈoːɹ\" rhyme=\"K\" rime=\"oːɹ\" type=\"weak\" vc_structure=\"V\">\n",
      "   And cried because his neck was sore,\n",
      "  </l>\n",
      "  <l n=\"15\" phon=\"ænd nˌɑːɾə wˈʌn sˈɛd sˈaɪʊɹ θˈɪŋz\" rhyme=\"L\">\n",
      "   And not a one said sour things\n",
      "  </l>\n",
      "  <l n=\"16\" phon=\"tʊ ˈɛnɪbˌɑːdi ˌɛni mˈoːɹ\" rhyme=\"K\" rime=\"oːɹ\" type=\"weak\" vc_structure=\"V\">\n",
      "   To anybody any more.\n",
      "  </l>\n",
      " </lg>\n",
      "</lg>\n"
     ]
    }
   ],
   "source": [
    "import re, subprocess, string\n",
    "import syllabify_ipa as sipa\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "infile = 'texts/emr/UnderTree/MUMPS.txt' #testing one poem for now\n",
    "#outfile = 'C:\\Users\\clair\\Dropbox\\photrans\\practice1.txt'\n",
    "\n",
    "def rhyme(wordA, wordB) :\n",
    "    \"\"\" Checks 2 phonetic strings to detect their rhyme.\"\"\"\n",
    "    \n",
    "    VOWELS = ['ə', 'ɚ', 'ɜː', 'əl',\n",
    "    'æ', 'ɐ', 'ɑː', 'ɑːɹ',\n",
    "    'ɛ', 'ɛɹ',\n",
    "    'ɪ', 'i', 'i:', 'ɪɹ',\n",
    "    'ʌ',\n",
    "    'u:', 'ʊ', 'ʊɹ',\n",
    "    'ɔː', 'ɔːɹ', 'oːɹ',\n",
    "    'aɪ', 'eɪ', 'ɔɪ', 'aʊ', 'oʊ', 'aɪə', 'aɪʊɹ']\n",
    "    CONSONANTS = ['p', 'b', 't','d', 'k', 'g',\n",
    "    'tʃ', 'dʒ',\n",
    "    'f', 'v', 'θ', 'ð', 's', 'z', 'ʃ', 'ʒ', 'h',\n",
    "    'm', 'n', 'ŋ',\n",
    "    'l', 'ɹ', 'j', 'w']\n",
    "    \n",
    "    #the Consonanat and Vowel lists are going to be used for comparison only\n",
    "    #so making them into a set will speed things up.\n",
    "    \n",
    "    v_set = set(VOWELS)\n",
    "    c_set = set(CONSONANTS)\n",
    "    \n",
    "    if len(wordA) <= len(wordB) :  #use shortest word as basis for comparison\n",
    "        basis = wordA\n",
    "        focus = wordB\n",
    "    else : \n",
    "        basis = wordB\n",
    "        focus = wordA\n",
    "        \n",
    "    segment = []   # holds matching segments\n",
    "    rphones = []   # holds the Rhyming Phones\n",
    "    \n",
    "    # This section matches letters working back-to-front until it gets to a \n",
    "    # non-match. It stores the matched segments as a rime, and the CV structure\n",
    "    # just because we can.\n",
    "    \n",
    "    rfocus = list(reversed(focus)) # make the focus word into a list\n",
    "    for num, letter in (enumerate(reversed(basis))) : # work through both words backwards\n",
    "        if letter != rfocus[num] :\n",
    "            break    # When sounds don't match, we stop comparing\n",
    "        else : # if base letter matches focus letter, \n",
    "            #print (letter, num)\n",
    "            rphones.append(letter) # add it to the list of matching letters\n",
    "            if letter in v_set :\n",
    "                segment.append('V')\n",
    "            else:\n",
    "                segment.append('C') # and add C/V to the list of matching segments\n",
    "                \n",
    "    segment.reverse()   # reverse the segment and rhyming phones for human readability\n",
    "    rphones.reverse()\n",
    "    \n",
    "    rphones = \"\".join(rphones)\n",
    "    rhymetype = \"\".join(segment) # make them into a string\n",
    "        \n",
    "    # Group rhyme types together\n",
    "    if rhymetype in ['', 'C'] :\n",
    "        group = 'none'\n",
    "    elif rhymetype in ['VC', 'VCC', 'VCCC', 'CVC', 'CVCC', 'CCVC'] :\n",
    "        group = 'strong'\n",
    "    elif rhymetype in ['V', 'CV', 'CCV', 'CVCV'] :\n",
    "        group = 'weak'\n",
    "    else :\n",
    "        group = 'unknown'\n",
    "        \n",
    "    #return rhyme info -- could return any info on rhyme we want\n",
    "    return [rphones, rhymetype, group]\n",
    "\n",
    "\n",
    "ab_string = string.ascii_uppercase # Create a string of all uppercase letters to use later\n",
    "ab_list = list(ab_string)          # Convert it to a list\n",
    "\n",
    "with open (infile, \"r\", encoding='utf-8-sig') as f : \n",
    "    soup = BeautifulSoup(f, 'xml')  # parsing as lxml loses the <head> tag\n",
    "    stanzas = soup.find_all(attrs={\"type\" : \"stanza\"}) #Get all the tags with type=stanza\n",
    "    \n",
    "    for stanza in stanzas :\n",
    "        lastsyllables = [] # list of last syllables in each line of the stanza\n",
    "        lines = stanza.find_all('l') #get all the lines in this stanza\n",
    "        \n",
    "        for line in lines :\n",
    "            target = line.text # get the text value using BS \n",
    "            \n",
    "            # and run the line through eSpeak with punctuation intact\n",
    "            cp = subprocess.run(['espeak', '-v', 'en-us', '-xq', '--ipa=3', target], \n",
    "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            phones = cp.stdout.decode(\"utf-8\").strip() # get eSpeak results in utf-8\n",
    "            phones = re.sub(\"\\r\\n\", \"\", phones) # remove any newlines in Windows\n",
    "            words = phones.split(' ') # split the line into words on spaces\n",
    "            \n",
    "            # Syllabify the last word split into phones\n",
    "            sylword = sipa.syllabify(words[-1].split('_'))\n",
    "            \n",
    "            # syllabify returns a list of lists [[onset],[nucleus],[coda]]. \n",
    "            # Codas but not onsets must fully match for normal rhyme.\n",
    "            # I keep the last syllable and push its sounds back together for now.\n",
    "            \n",
    "            lastsyllable = ' '.join(' '.join(''.join(p) for p in syl) for syl in sylword[-1])\n",
    "            lastsyllable = lastsyllable.strip().replace('ˈ', '') # remove f & r spaces and primary stress\n",
    "            lastsyllables.append(lastsyllable.split(' ')) # put the last syl on the list of last syls.\n",
    "\n",
    "            \n",
    "            phones = re.sub(\"_\", \"\", phones) # remove underscores to make pretty print\n",
    "            line.attrs['phon'] = phones #assigns a new attribute to the <line> for the transcription\n",
    "            \n",
    "        # Each stanza will have its own set of rhymes and rhyme data. This decision can be changed\n",
    "        # by removing the verse loop and doing the whole poem at once. Right now the same rhyme in\n",
    "        # different stanzas will get different letters. Unrhymed lines get their own letter. \n",
    "        # We could change this so the unrhymed lines get X or something else. \n",
    "\n",
    "        rime_dict = {}            # This will be the dictionary of rimes for each verse\n",
    "        skip = []                 # list of rhyme tests to skip\n",
    "        size = len(lastsyllables) # should match num of lines in the verse\n",
    "        for i in range(size-1) :  # It takes 2 to rhyme so last line doesn't need testing.\n",
    "            for j in range(i+1, size) : # Same for the target list--don't include first line.\n",
    "                if j in skip :    # skip any rhymes already found\n",
    "                    continue\n",
    "                [rime, cv, grp] = rhyme(lastsyllables[i], lastsyllables[j])\n",
    "                if grp != 'none' :\n",
    "                    skip.append(j) # when a rhyme is found, put it on the skip list\n",
    "                    if rime not in rime_dict :\n",
    "                        rime_dict[rime] = [cv,grp,i,j]\n",
    "                    else:\n",
    "                        rime_dict[rime].extend([i,j]) # this way all the rhymed lines are on one list\n",
    "                                \n",
    "        # We have located all the rhymes. Now assign them a letter and put\n",
    "        # them into the TEI markup\n",
    "        \n",
    "        completed_lines = []  # to hold list of lines that are marked up so we don't repeat them.\n",
    "        for l in range(size) :  # loop through the indexes of line numbers\n",
    "            if l in completed_lines :  # skip any lines that have been assigned letters already\n",
    "                    continue\n",
    "                    \n",
    "            # If a rhyme has been discovered, the line number will be in the list of values\n",
    "            # associated with the rime. Get that key and use it to get the values again. \n",
    "            # Each rime is in once, so the list of keys for any line should be 1\n",
    "            \n",
    "            rhymed_keys = {key for key, value in rime_dict.items() if l in value}\n",
    "            rkeylist = list(rhymed_keys)\n",
    "            if rkeylist != [] :  # if there are some rhymes...\n",
    "                cv, grp, *found = rime_dict[rkeylist[0]] # convert rime+ list to digits\n",
    "                found = list(set(found)) # converting to a set() eliminates copies\n",
    "                next_let = ab_list.pop(0) # assign rime the next alphabet letter\n",
    "            \n",
    "                # For each line that rhymes together, put infor in xml and put it\n",
    "                # on a skip list so it won't get changed later.\n",
    "            \n",
    "                for fi in found : \n",
    "                    lines[fi].attrs['type'] = grp\n",
    "                    lines[fi].attrs['rhyme'] = next_let\n",
    "                    lines[fi].attrs['rime'] = rkeylist[0]\n",
    "                    lines[fi].attrs['vc_structure'] = cv\n",
    "                    completed_lines.append(fi)\n",
    "                continue\n",
    "            else :\n",
    "                # If the line doesn't rhyme, give it its own letter\n",
    "                next_let = ab_list.pop(0)\n",
    "                lines[l].attrs['rhyme'] = next_let             \n",
    "\n",
    "# After all the verses are done, print out the poem.\n",
    "\n",
    "print(soup.prettify())\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espeak prepends two spaces--not sure what they are. One might be the BOM mark that then gets cleared by the decode statement. Espeak introduces a line break to execute pauses in speech. We only need line endings for end-rhyme analysis. I removed all the other breaks. \n",
    "\n",
    "I thought that another way to go wih this whole deal would be to capture the output at a more advanced level. For MBROLA voices, eSpeak outputs detailed speech info for every segment, including intonation contours, but NOT syllable position. So I found a module that syllabifies English pretty well. Any internal rhyming that does not occur in a final syllable will have to be done by pure matching.\n",
    "\n",
    "Finding rhymes is basically a matching exercise. For a first pass we can get the last X characters in each line into a list, then find any matches going forward. Since the poems in this book all utilize rhyme patterns by verse, I focused on getting rhymes from individual verses.\n",
    "\n",
    "Note: I've noticed eSpeak doesn't use voiceless w, (turned w like \"which\" or \"whale\") and I'm sure EMR with a Chicago MA would have used that, so we might want to tweak the voice a bit. \n",
    "Note: eSpeak outputs double IPA characters for some signs, specifically affricates and diphthongs. They provide three workarounds:  \n",
    "--ipa=1 Uses ties (U+0361) for phoneme names of more than one letter.  \n",
    "--ipa=2 Uses Zero Width Joiner (U+200D) for phoneme names of more than one letter.  \n",
    "--ipa=3 Separate phoneme names with underscore characters.  \n",
    "Each one can be used by us but we just need to be consistent. It might be easiest to split words on underscores tp compare sounds, while just deleting underscores in order to print nice phonetics. I went with ipa=3.\n",
    "\n",
    "So, as an arbitrary decision, let's see if we can make a single copy of each poem, marked up in very simple TEI, that includes the full orthographic and full IPA transliteration and labled rhyme scheme. If we have that we can easily get out static pages with different info, or come up with PHP or JavaScript methods of interactive display. To start this process I'm going back to the little program I made to separate the poems, and use that to insert some XML codes. Then we can use the XML to help process the rhyme schemes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
