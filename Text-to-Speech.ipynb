{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text-to-Phonemes\n",
    "\n",
    "For English, unlike some languages (German or Turkish, for example), getting phonological information from regular script is next to impossible. To do things that need to use spoken language as a basis for analysis, we need to convert text to a phonological transcription. Computation has come a long way on this issue, so there's no need to reinvent the wheel. The best solution is to use an off-the-shelf \"Text-to-Speech\" (TTS) engine. Most of these engines work the same way. They have a big dictionary of frequent words, then some rules for inferring the pronunciation of infrequent words (including names). The engine outputs what is essentially a script for a TTS program to pronounce. \n",
    "\n",
    "Several engines exist that allow one to capture the engine output at various stages for ones own purposes. The CMU pronouncing dictionary is included in Python's NLTK. I have chosen to use  eSpeak, however, because it outputs International Phonetic Alphabet (IPA), its inferencing system is robust--it leaves no words untranscribed--and it is easy to use.\n",
    "\n",
    "To prepare eSpeak, go to the developer's site, http://espeak.sourceforge.net/download.html, click on download, and download the version for your OS. It will be a zipped file, so unzip it and run the install program into a directory near your python projects directory. Write down the directory so you don't forget it! \n",
    "\n",
    "In my work process I run eSpeak from the command line. It is possible to write a Python script that will run eSpeak for you, but that is a lot of trouble to do something so easy. Instead, in my eSpeak directory I keep a plain text file of frequently used commands, so I can just copy and paste those. For our purposes, you will only need to run it once or twice per file -- it is working with the outputs that will take most of the time.\n",
    "\n",
    "Use your file browser to view the folder where you installed eSpeak. Inside that folder should be four more folders: command_line, dictsource, docs, and espeak-data. The docs folder contains html documentation. You can open `docindex.html` in your browser to view the Help contents. On the left menu is the Usage link. That page will show you how to use the program. (All of the help documents are online at the eSpeak site as well.)\n",
    "\n",
    "To make sure the program is working, open a terminal. (You can do this from your Jupyter homepage in your browser. Near the top, on the right, clicking the NEW button will get you a drop down menu. One item on it is \"terminal.\" Choose that one.) It will probably open up inside your home directory, in your Users folder if you are in Windows. Change your directory ('cd' in Windows) to your `eSpeak/command_line` directory. Once you are inside there, type 'espeak' and after you hit return the program will begin. Type some words and it will say them after you hit enter. Here is what mine looked like\n",
    "\n",
    ">`PS C:\\Users\\clair> cd C:\\Users\\clair\\Dropbox\\photrans\\eSpeak\\command_line\n",
    "PS C:\\Users\\clair\\Dropbox\\photrans\\eSpeak\\command_line> espeak\n",
    "hello world\n",
    "I hear a voice.\n",
    "I hear a voice!`\n",
    "\n",
    "Ctrl-C will end the program (again, in Windows. Mac is probably different).\n",
    "\n",
    "You can also fire the program up with a sentence in quotes, which it will read then exit.\n",
    "\n",
    ">`PS C:\\Users\\clair\\Dropbox\\photrans\\eSpeak\\command_line> espeak \"Hello World!\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running eSpeak\n",
    "\n",
    "Most important for us, eSpeak will also read from file. You need to get yourself a practice file to work with. I made a copy of Yeats's \"Adam's Curse\" and stored it as curse.txt. To run eSpeak on a file, you feed it some \"switches\" so that it ouputs what you want. This is the command I will use \n",
    "\n",
    ">`espeak -q -x -f \"C:\\Users\\clair\\Documents\\2021Workbooks\\workbooks-master\\texts\\curse.txt\" --ipa=3 --phonout=\"C:\\Users\\clair\\Dropbox\\photrans\\practice1.txt\" -v en-us`\n",
    "\n",
    "Explanation: \n",
    ">`-q` is quiet mode (I don't need to hear it read the poem)   \n",
    "`-x` the phonemes are written to standard output, not sent to the computer speaker  \n",
    "`-f <filename>` the file to translate. I put the name in double quotes. Here I am using the full path because I am still in the espeak\\command_line directory, so I need the program to find the file easily.  \n",
    "`--ipa` tells it to output in IPA rather than pseudo-sound code.  \n",
    "`--phonout=<filename>` Output file. Again using quotation marks, I use the full path and file name for the file I want to create.  \n",
    "`-v en-us` The -v switch tells it which voice to use, and I want English-US. There are a number of different voices you can use, and you can vary their pitch and speed. You can also make up your own voices and load them--I will leave that to you if you want to do it! Other switches and commands can be found on the Usage page. \n",
    "\n",
    "I usually build the whole command in a plain text editor, then copy and paste it into the terminal. When you hit enter, in almost no time at all your output file should appear in your folder. I can open mine in Notepad++ because it is set to display UTF-8. If you open the file and see lots of junk signs (not IPA!) you should get or configure your text editor to display unicode. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "Here is the first few lines of my output file:\n",
    "\n",
    ">`wiː sˈæt təɡˌɛðɚɹ æt wˈʌn sˈʌmɚz ˈɛnd\n",
    " ðæt bjˈuːɾɪfəl mˈaɪld wˈʊmən\n",
    " jʊɹ klˈoʊs fɹˈɛnd\n",
    " ænd juː ænd ˈaɪ\n",
    " ænd tˈɔːkt ʌv pˈoʊɪtɹi`\n",
    " \n",
    ">WE sat together at one summer's end,  \n",
    "That beautiful mild woman, your close friend,  \n",
    "And you and I, and talked of poetry.  \n",
    "\n",
    "Some things to notice about the ouput:  \n",
    "1. Phonemes of words are together, with spaces between the words.  \n",
    "2. Primary (ˈ) and some secondary (ˌ) stresses are included  \n",
    "3. The program writes lines out as breath units as dictated by commas and periods,\n",
    "so you can use it to manipulate output as you want it. It also 'reads' out punctuation that is inside quotation marks, so in most cases you will want to delete them in pre-processessing.  \n",
    "\n",
    "The output will create some results that might seem odd to you in some cases. For example, the American voices will mimic the habit of some Americans to run some words together. Here for example are the final 2 lines:\n",
    "\n",
    ">`ðˌɐɾɪt hɐd ˈɔːl sˈiːmd hˈæpi  \n",
    " ænd jˈɛt wiːd ɡɹˈoʊn æz wˈɪɹihˈɑːɹɾᵻd æz ðæt hˈɑːloʊ mˈuːn`  \n",
    " \n",
    ">That it had all seemed happy, and yet we'd grown  \n",
    "As weary-hearted as that hollow moon.  \n",
    "\n",
    "The two lines are enjambed, so everything after the comma is on one line. Also, the first two words of the line, *that it*, are both unstressed, so they are run together as one word. This may or may not be an issue for your project. Some of these things can be manipulated by altering punctuation or changing voices. \n",
    "\n",
    "If you re-run it with `-v en`, omitting the US designation, you will find that the default English output is a British accent that is non-rhotic. You will get \"aʊəz\" for *hours* and \"jɔː\" for *your*. (**Pro-Tip**: in your terminal window, the up arrow key will cycle back through your most recent commands. You can use the left and right arrows to go through a command and edit the parts you want to change.) \n",
    "\n",
    "There are a handful of sounds, **diphthongs** and **affricates**, that are represented in older IPA fonts by two consecutive signs. If you are hunting rhymes, this might throw off your schemes. The beginning and ending sounds of the word *church*, for example, are voiceless alveo-palatal affricates. They show up in the poem as `stˈɪtʃɪŋ ænd ʌnstˈɪtʃɪŋ` \"stitching and unstitching.\" If you were looking for rhymes on `ɪt`, then these would be counted. To fix this, you can run the --ipa switch with 1 (--ipa=1) to get a tie between all multiple character sounds -- `stˈɪt͡ʃɪŋ ænd ʌnstˈɪt͡ʃɪŋ`. Or you could run it with 3 (--ipa=3) to put an underscore between every sound in a word -- `s_t_ˈɪ_tʃ_ɪ_ŋ__ æ_n_d ʌ_n_s_t_ˈɪ_tʃ_ɪ_ŋ`. Either way will prevent the issue. Make sure you run all your files the same way, so any filters you build based on the output will work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing\n",
    "\n",
    "So what can you do with these files? First, we use the codecs module, which is what Python uses to handle encoding issues. We can use our normal file opening, but use `codecs.open()` to open our file. The output of eSpeak is UTF-8 so we pass `codecs.open()` the file name and the encoding parameter \"utf-8\". Bingo, we get our list of words that we can make into out nltk.Text object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wiː', 'sˈæt', 'təɡˌɛðɚɹ', 'æt', 'wˈʌn', 'sˈʌmɚz', 'ˈɛnd', 'ðæt', 'bjˈuːɾɪfəl', 'mˈaɪld']\n"
     ]
    }
   ],
   "source": [
    "import codecs \n",
    "\n",
    "file = \"texts/curse-ipa.txt\"\n",
    "\n",
    "with codecs.open (file, encoding=\"utf-8\") as f:\n",
    "  curse = f.read()\n",
    "\n",
    "words = curse.split()\n",
    "print (words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "curseText = nltk.Text(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do what are used to doing, but reading IPA. How about doing a concordance on 'love'? We use our usual command. Wait--how do we type in the IPA? The easiest way to do it is to go to your text editor and copy/paste. Another way is to use the neat website TypeIPA at https://ipa.typeit.org/. There you can pick out the signs and copy/paste them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 4 of 4 matches:\n",
      "ɪbɜːɹɪŋ ðɛɹ hɐvbɪn lˈʌvɚz hˌuː θˈɔːt lˈʌv ʃˌʊd bˈiː sˈoʊ mˌʌtʃ kɑːmpˈaʊndᵻd ʌv\n",
      "ː sˈæt ɡɹˈoʊn kwˈaɪət æt ðə nˈeɪm ʌv lˈʌv wiː sˈɔː ðə lˈæst ˈɛmbɚz ʌv dˈeɪlaɪt\n",
      "wɜː bjˈuːɾɪfəl ænd ðæt aɪ stɹˈoʊv tə lˈʌv juː ɪnðɪ ˈoʊld hˈaɪ wˈeɪ ʌv lˈʌv ðˌɐ\n",
      " tə lˈʌv juː ɪnðɪ ˈoʊld hˈaɪ wˈeɪ ʌv lˈʌv ðˌɐɾɪt hɐd ˈɔːl sˈiːmd hˈæpi ænd jˈɛ\n"
     ]
    }
   ],
   "source": [
    "word = \"lˈʌv\"\n",
    "curseText.concordance(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realistically, you probably don't want to do things with IPA transcripts that you can do easily with orthographic transcripts, so I doubt NLTK will be much help further along. Something you might want to do would be to count end rhyme forms. This would involve going through each line, getting the final rime--V(C)--vowel and optional final consonant), and seeing if it matches the rime one or two lines down. Let's give it a try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
