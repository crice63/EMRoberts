{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put Espeak\\command_line\\ in my PATH so no need for full path to run.\n",
    "The espeak args are a list. Apparently it is best to build the whole list from vars.\n",
    "My Anaconda is -V 3.6.7, so can't use the `capture_output` parameter added in 3.7. The `universal_newlines` parameter causes an encoding fault in subprocess somewhere, so I decode stdout manually after it returns. That is also why the rstrip() is needed, to remove the \\r\\n. I don't know if decode removes the utf8 byte at the front of each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɛ_k_s_k_l_ˈuː_d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-ɛ-k.skl-ˈuː-d'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import syllabify_ipa as s\n",
    "text = \"exclude\"\n",
    "#outfile = 'C:\\Users\\clair\\Dropbox\\photrans\\practice1.txt'\n",
    "cp = subprocess.run(['espeak', '-v', 'en-us', '-q', '-X', '--ipa=3', text], \n",
    "                    stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "ipatext = cp.stdout.decode(\"utf-8\").strip()\n",
    "print (ipatext)\n",
    "syltext = s.syllabify(ipatext.split('_'))\n",
    "s.pprint(syltext)\n",
    "#print(VOWELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the above produces speech from my computer speaker (if the quiet flag, -q, is omitted), and has the unicode IPA output in a variable. I also found a program to syllabify the ipa forms. We should work line by line so that if espeak runs any words together or breaks the line into parts due to punctuation then we won't have to deal with it right away. We can get the line of poetry, get the IPA version, call them a line, and store it or print it. This partly depends on the front end desired on the Society webpage. Lets pause to get the Book into poems so we can run poems one at a time.\n",
    "\n",
    "Got that done. Poems are in 'texts/emr/UnderTree/' with some TEI tags. This eases things because we can use the tree structure to get specific parts. There's a poem called HORSE.txt that has quoted speech so let's work with that one. Infile is hard coded to start.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<lg n=\"25\" type=\"poem\" xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
      " <head>\n",
      "  MUMPS\n",
      " </head>\n",
      " <lg n=\"1\" type=\"stanza\">\n",
      "  <l n=\"1\" phon=\"aɪ hɐd ɐ fˈiːlɪŋ ɪn maɪ nˈɛk\" rhyme=\"A\">\n",
      "   I had a feeling in my neck,\n",
      "  </l>\n",
      "  <l n=\"2\" phon=\"ænd ɑːnðə sˈaɪdz wɜː tˈuː bˈɪɡ bˈʌmps\" rhyme=\"B\" rime=\"ʌmps\" type=\"strong\" vc_structure=\"VCCC\">\n",
      "   And on the sides were two big bumps;\n",
      "  </l>\n",
      "  <l n=\"3\" phon=\"aɪ kˌʊdənt swˈɑːloʊ ˈɛnɪθˌɪŋ\" rhyme=\"C\">\n",
      "   I couldn't swallow anything\n",
      "  </l>\n",
      "  <l n=\"4\" phon=\"æt ˈɔːl bɪkˈʌz aɪ hɐd ðə mˈʌmps\" rhyme=\"B\" rime=\"ʌmps\" type=\"strong\" vc_structure=\"VCCC\">\n",
      "   At all because I had the mumps.\n",
      "  </l>\n",
      " </lg>\n",
      " <lg n=\"2\" type=\"stanza\">\n",
      "  <l n=\"5\" phon=\"ænd mˈʌðɚ tˈaɪd ɪt wɪð ɐ pˈiːs\" rhyme=\"D\">\n",
      "   And Mother tied it with a piece,\n",
      "  </l>\n",
      "  <l n=\"6\" phon=\"ænd ðˈɛn ʃiː tˈaɪd ˌʌp wɪl ænd dʒˈɑːn\" rhyme=\"E\" rime=\"ɑːn\" type=\"strong\" vc_structure=\"VC\">\n",
      "   And then she tied up Will and John,\n",
      "  </l>\n",
      "  <l n=\"7\" phon=\"ænd nˈoʊwˈʌn ˈɛls bˌʌt dˈɪk wʌz lˈɛft\" rhyme=\"F\">\n",
      "   And no one else but Dick was left\n",
      "  </l>\n",
      "  <l n=\"8\" phon=\"ðæt dˈɪdnt hæv ɐ mˈʌmp ɹˈæɡ ˈɑːn\" rhyme=\"E\" rime=\"ɑːn\" type=\"strong\" vc_structure=\"VC\">\n",
      "   That didn't have a mump rag on.\n",
      "  </l>\n",
      " </lg>\n",
      " <lg n=\"3\" type=\"stanza\">\n",
      "  <l n=\"9\" phon=\"hiː tˈiːzd æt ˌʌs ænd lˈæfd æt ˌʌs\" rhyme=\"G\">\n",
      "   He teased at us and laughed at us,\n",
      "  </l>\n",
      "  <l n=\"10\" phon=\"ænd sˈɛd wɛnˌɛvɚ hiː wɛnt bˈaɪ\" rhyme=\"H\" rime=\"aɪ\" type=\"weak\" vc_structure=\"V\">\n",
      "   And said, whenever he went by,\n",
      "  </l>\n",
      "  <l n=\"11\" phon=\" ɪts vˈɪnᵻɡɚ ænd lˈɛmən dɹˈɑːps\" rhyme=\"I\">\n",
      "   \"It's vinegar and lemon drops\n",
      "  </l>\n",
      "  <l n=\"12\" phon=\"ænd pˈɪkəlz dʒˈʌst tə mˌeɪk ˌʌs kɹˈaɪ\" rhyme=\"H\" rime=\"aɪ\" type=\"weak\" vc_structure=\"V\">\n",
      "   And pickles!\" just to make us cry.\n",
      "  </l>\n",
      " </lg>\n",
      " <lg n=\"4\" type=\"stanza\">\n",
      "  <l n=\"13\" phon=\"bˌʌt tˈuːzdeɪ dˈɪk wʌz vˈɛɹi sˈæd\" rhyme=\"J\">\n",
      "   But Tuesday Dick was very sad\n",
      "  </l>\n",
      "  <l n=\"14\" phon=\"ænd kɹˈaɪd bɪkˈʌz hɪz nˈɛk wʌz sˈoːɹ\" rhyme=\"K\" rime=\"oːɹ\" type=\"weak\" vc_structure=\"V\">\n",
      "   And cried because his neck was sore,\n",
      "  </l>\n",
      "  <l n=\"15\" phon=\"ænd nˌɑːɾə wˈʌn sˈɛd sˈaɪʊɹ θˈɪŋz\" rhyme=\"L\">\n",
      "   And not a one said sour things\n",
      "  </l>\n",
      "  <l n=\"16\" phon=\"tʊ ˈɛnɪbˌɑːdi ˌɛni mˈoːɹ\" rhyme=\"K\" rime=\"oːɹ\" type=\"weak\" vc_structure=\"V\">\n",
      "   To anybody any more.\n",
      "  </l>\n",
      " </lg>\n",
      "</lg>\n"
     ]
    }
   ],
   "source": [
    "import re, subprocess, string\n",
    "import syllabify_ipa as sipa\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "infile = 'texts/emr/UnderTree/MUMPS.txt' #testing one poem for now\n",
    "#outfile = 'C:\\Users\\clair\\Dropbox\\photrans\\practice1.txt'\n",
    "\n",
    "\n",
    "\n",
    "def rhyme(wordA, wordB) :\n",
    "    \"\"\" Checks 2 phonetic strings to detect their rhyme.\"\"\"\n",
    "    \n",
    "    VOWELS = ['ə', 'ɚ', 'ɜː', 'əl',\n",
    "    'æ', 'ɐ', 'ɑː', 'ɑːɹ',\n",
    "    'ɛ', 'ɛɹ',\n",
    "    'ɪ', 'i', 'i:', 'ɪɹ',\n",
    "    'ʌ',\n",
    "    'u:', 'ʊ', 'ʊɹ',\n",
    "    'ɔː', 'ɔːɹ', 'oːɹ',\n",
    "    'aɪ', 'eɪ', 'ɔɪ', 'aʊ', 'oʊ', 'aɪə', 'aɪʊɹ']\n",
    "    CONSONANTS = ['p', 'b', 't','d', 'k', 'g',\n",
    "    'tʃ', 'dʒ',\n",
    "    'f', 'v', 'θ', 'ð', 's', 'z', 'ʃ', 'ʒ', 'h',\n",
    "    'm', 'n', 'ŋ',\n",
    "    'l', 'ɹ', 'j', 'w']\n",
    "    \n",
    "    #the Consonanat and Vowel lists are goin to be used for comparison only\n",
    "    #so making them into a set will speed things up.\n",
    "    \n",
    "    v_set = set(VOWELS)\n",
    "    c_set = set(CONSONANTS)\n",
    "    \n",
    "    if len(wordA) <= len(wordB) :  #use shortest word as basis for comparison\n",
    "        basis = wordA\n",
    "        focus = wordB\n",
    "    else : \n",
    "        basis = wordB\n",
    "        focus = wordA\n",
    "        \n",
    "    segment = []   # holds matching segments\n",
    "    rphones = []   # holds the Rhyming Phones\n",
    "    \n",
    "    for num, letter in (enumerate(reversed(basis))) : # work through words backwards\n",
    "        rfocus = list(reversed(focus)) # make the focus word into a list\n",
    "        \n",
    "        if letter != rfocus[num] :\n",
    "            break    # When sounds don't match, we stop comparing\n",
    "        if letter == rfocus[num] : # if base letter matches focus letter, \n",
    "            #print (letter, num)\n",
    "            rphones.append(letter) # add it to the list of matching letters\n",
    "            if letter in v_set :\n",
    "                segment.append('V')\n",
    "            else:\n",
    "                segment.append('C') # and add C/V to the list of matching segments\n",
    "                \n",
    "    segment.reverse()   # reverse the segment and rhyming phones for human readability\n",
    "    rphones.reverse()\n",
    "    \n",
    "    rphones = \"\".join(rphones)\n",
    "    rhymetype = \"\".join(segment) # make it into a string\n",
    "    #print (rhymetype)\n",
    "    \n",
    "    # Group rhyme types together\n",
    "    if rhymetype in ['', 'C'] :\n",
    "        group = 'none'\n",
    "    elif rhymetype in ['VC', 'VCC', 'VCCC', 'CVC', 'CVCC', 'CCVC'] :\n",
    "        group = 'strong'\n",
    "    elif rhymetype in ['V', 'CV', 'CCV', 'CVCV'] :\n",
    "        group = 'weak'\n",
    "    else :\n",
    "        group = 'unknown'\n",
    "    #return rhyme info -- could return any info on rhyme we want\n",
    "    return [rphones, rhymetype, group]\n",
    "\n",
    "\n",
    "\n",
    "ab_string = string.ascii_uppercase # Create a string of all uppercase letters to use later\n",
    "ab_list = list(ab_string) # Convert it to a list of all uppercase letters\n",
    "\n",
    "with open (infile, \"r\", encoding='utf-8-sig') as f : \n",
    "    soup = BeautifulSoup(f, 'xml')  #parsing as lxml loses the <head> tag\n",
    "    stanzas = soup.find_all(attrs={\"type\" : \"stanza\"}) #Get all the tags with type=stanza\n",
    "    \n",
    "    for stanza in stanzas :\n",
    "        lastsyllables = [] # list of last syllables in each line of the stanza\n",
    "        lines = stanza.find_all('l') #get all the lines in this stanza\n",
    "        \n",
    "        for line in lines :\n",
    "            target = line.text # get the text value using BS and run it through eSpeak\n",
    "            cp = subprocess.run(['espeak', '-v', 'en-us', '-xq', '--ipa=3', target], \n",
    "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            phones = cp.stdout.decode(\"utf-8\").strip() # get eSpeak results\n",
    "            phones = re.sub(\"\\r\\n\", \"\", phones) # remove any newlines in Windows\n",
    "            words = phones.split(' ') # split the line into words on spaces\n",
    "            \n",
    "            # Syllabify the last word split into phones\n",
    "            sylword = sipa.syllabify(words[-1].split('_'))\n",
    "            \n",
    "            # syllabify returns a list of lists [[onset],[nucleus],[coda]]. Codas but not onsets must fully\n",
    "            # match in order to rhyme. I get the last syllable and push the sounds back together for now.\n",
    "            lastsyllable = ' '.join(' '.join(''.join(p) for p in syl) for syl in sylword[-1])\n",
    "            lastsyllable = lastsyllable.strip().replace('ˈ', '') # remove f & r spaces and primary stress\n",
    "            lastsyllables.append(lastsyllable.split(' ')) # put the last syl on the list of last syls.\n",
    "\n",
    "            \n",
    "            phones = re.sub(\"_\", \"\", phones) # remove underscores to make pretty print\n",
    "            line.attrs['phon'] = phones #assigns a new attribute to the <line> for the transcription\n",
    "            \n",
    "        # each stanza will have its own set of rhymes and rhyme data. This decision can be changed\n",
    "        # by removing the verse loop and doing the whole poem at once. Right now the same rhyme in\n",
    "        # different stanzas will get different letters. \n",
    "\n",
    "        rime_dict = {}\n",
    "        skip = [] # list of rhyme tests to skip\n",
    "        size = len(lastsyllables) # should match num of lines in the verse\n",
    "        for i in range(size-1) : \n",
    "            for j in range(i+1, size) : \n",
    "                if j in skip : # skip any rhymes already found\n",
    "                    continue\n",
    "                [rime, cv, grp] = rhyme(lastsyllables[i], lastsyllables[j])\n",
    "                if grp != 'none' :\n",
    "                    skip.append(j) # when a rhyme is found, put it on the skip list\n",
    "                    if rime not in rime_dict :\n",
    "                        rime_dict[rime] = [cv,grp,i,j]\n",
    "                    else:\n",
    "                        rime_dict[rime].extend([i,j]) # this way all the rhymed lines are on one list\n",
    "        #print(rime_dict)\n",
    "        #print(\"Next stanza\")\n",
    "        \n",
    "        # We have located all the rhymes. Now time to assign them a letter and put\n",
    "        # them into the TEI markup\n",
    "        \n",
    "        completed_lines = []  # to hold list of lines that are marked up so we don't repeat them.\n",
    "        for l in range(size) :  # loop through the indexes of line numbers\n",
    "            if l in completed_lines :  # skip any lines that have been assigned letters already\n",
    "                    continue\n",
    "                    \n",
    "            # If a rhyme has been discovered, the line number will be in the list of values\n",
    "            # associated with the rime. Get that key and use it to get the values again.\n",
    "            \n",
    "            rhymed_keys = {key for key, value in rime_dict.items() if l in value}\n",
    "            rkeylist = list(rhymed_keys)\n",
    "            if rkeylist != [] :  # if there are some rhymes...\n",
    "                cv, grp, *found = rime_dict[rkeylist[0]] # convert rime+ list to digits\n",
    "                found = list(set(found)) # converting to a set() eliminates copies\n",
    "                next_let = ab_list.pop(0) # assign rime the next alphabet letter\n",
    "                for fi in found : \n",
    "                    lines[fi].attrs['type'] = grp\n",
    "                    lines[fi].attrs['rhyme'] = next_let\n",
    "                    lines[fi].attrs['rime'] = rkeylist[0]\n",
    "                    lines[fi].attrs['vc_structure'] = cv\n",
    "                    completed_lines.append(fi)\n",
    "                continue\n",
    "            else :\n",
    "                next_let = ab_list.pop(0)\n",
    "                lines[l].attrs['rhyme'] = next_let             \n",
    "\n",
    "\n",
    "print(soup.prettify())\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espeak prepends two spaces--not sure what they are. One might be the BOM mark that then gets cleared by the decode statement. Espeak introduces a line break to execute pauses in speech. We only need line endings for end-rhyme analysis. I removed all the other breaks. \n",
    "\n",
    "I thought that another way to go wih this whole deal would be to capture the output at a more advanced level. For MBROLA voices, eSpeak outputs detailed speech info for every segment, including intonation contours, but NOT syllable position. So I found a module that syllabifies English pretty well. Any internal rhyming that does not occur in a final syllable will have to be done by pure matching.\n",
    "\n",
    "Finding rhymes is basically a matching exercise. For a first pass we can get the last X characters in each line into a list, then find any matches going forward. Since the poems in this book all utilize rhyme patterns by verse, I focused on getting rhymes from individual verses.\n",
    "\n",
    "Note: I've noticed eSpeak doesn't use voiceless w, (turned w like \"which\" or \"whale\") and I'm sure EMR with a Chicago MA would have used that, so we might want to tweak the voice a bit. \n",
    "Note: eSpeak outputs double IPA characters for some signs, specifically affricates and diphthongs. They provide three workarounds:  \n",
    "--ipa=1 Uses ties (U+0361) for phoneme names of more than one letter.  \n",
    "--ipa=2 Uses Zero Width Joiner (U+200D) for phoneme names of more than one letter.  \n",
    "--ipa=3 Separate phoneme names with underscore characters.  \n",
    "Each one can be used by us but we just need to be consistent. It might be easiest to split words on underscores tp compare sounds, while just deleting underscores in order to print nice phonetics. I went with ipa=3.\n",
    "\n",
    "So, as an arbitrary decision, let's see if we can make a single copy of each poem, marked up in very simple TEI, that includes the full orthographic and full IPA transliteration and labled rhyme scheme. If we have that we can easily get out static pages with different info, or come up with PHP or JavaScript methods of interactive display. To start this process I'm going back to the little program I made to separate the poems, and use that to insert some XML codes. Then we can use the XML to help process the rhyme schemes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
